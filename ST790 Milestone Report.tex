\documentclass[12pt]{article}

\usepackage[top = 2cm, bottom = 2cm, left = 2cm, right = 2cm]{geometry}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\title{Denoising with subspace learning\\ST790 Milestone Report}
\author{Bowen Liu, Renfei Gong, Haoyu Chen}

%\setcounter{secnumdepth}{-2}

\newcommand{\Real}{\mathbb{R}}
\renewcommand{\d}{\mathrm{d}}
\newcommand{\Expect}{\mathbf{E}}
\newcommand{\Tra}{^{\top}}
\newcommand{\tr}{\operatorname{tr}}
\newcommand{\V}[1]{{\mathbf{\MakeLowercase{#1}}}}
\newcommand{\VE}[2]{\MakeLowercase{#1}_{#2}}
\newcommand{\Vn}[2]{\V{#1}^{(#2)}}
\newcommand{\Vhat}[1]{\hat{\mathbf{\MakeLowercase{#1}}}}


\begin{document}
	
	\maketitle
	
	\section{Introduction}
	
	Image noise are produced when being created, saved, transmitted or presented. In order to restore a corrupted image, various optimization methods are at hand (Chi et al., 2013), and most of them reqiure the knowledge of noise position to achieve a better performance. In most cases, however, we have no information about the exact positions of noise pixels, and common optimization methods do no better than blur the corrupted image. Inspired by minimizing nuclear norm method, we found dimensionality reduction technique can lower the noise in a significant way. In fact, random noise points often increase the rank of the original image matrix, and reducing rank can fix this problem. Hence our denoising problem is actually subspace learning with corrupted information. 
	
	\subsection{The PCA approach}
	A traditional dimensionality reduction method with full information is Principal Component Analysis (PCA). We will first introduce the subspace learning problem in a PCA setting.
	
	Let $\V{x}^{(1)}, \ldots, \V{x}^{(n)}$ be the column vectors in an image. In this project, we assume that $\V{x}^{(1)}, \ldots, \V{x}^{(n)}$ are iid with some certain distribution. In the expressions below, the vector $\V{x}$ refers to a vector with the same distribution as $\V{x}^{(i)}$.
	Let $\Pi$ denote a projection matrix from $\Real^p$ to an $r-$dimensional subspace. Our goal is to find such a projection matrix that minimize the mean square error
	$$
	f(\Pi) = \Expect \|\V{x} - \Pi\V{x} \|_2^2 = \Expect \left( \|\V{x} \|_2^2 -\V{x}\Tra\Pi\V{x} \right)
	= \Expect \left( \|\V{x} \|_2^2 \right) - \langle \Pi, \Expect (\V{x}\V{x}\Tra)\rangle,
	$$
	where the inner product of two matrices $\langle A, B\rangle$ is defined as $\langle A, B\rangle = \tr(A\Tra B)$. Since the first term $\Expect \left( \|\V{x} \|_2^2 \right)$ is free of $\Pi$, our goal is to minimize $-\langle \Pi, \Expect (\V{x}\V{x}\Tra)\rangle$, or to maximize $\langle \Pi, \Expect (\V{x}\V{x}\Tra)\rangle$. Denote $\Expect (\V{x}\V{x}\Tra)$ by $C$, and the PCA approach to maximize $\langle \Pi, C\rangle$ is to take $\Pi = \sum_{i=1}^k \V{v}_i \V{v}_i\Tra$, where $\V{v}_1, \ldots, \V{v}_k$ are the $k$ leading eigenvectors of $C$. Before implementing the PCA approach, we need to find an estimator for $C$.
	
	\section{Our Contribution}
	\subsection{Realizing POPCA}
	In subspace learning problem where we have no control on which attributes are missing, Gonen et al. (2016) derived Partially Observed PCA (POPCA) method to account for the missing values. That is,
	if denote $\Vhat{x}$ as the observed values of true $\V{x}$, we assume that
	\[
	\Vhat{x}_i = 
	\begin{cases}
	\V{x}_i, & \textrm{w.p. } 1-p \\
	0, & \textrm{w.p. } p
	\end{cases}
	\]
	to get an unbiased estimator for matrix $C$, Mitliagkas et al. (2014) gives
	\[
	\hat{C}_{ij} = 
	\begin{cases}
	\frac{1}{(1-p)^2} \Vhat{x}_i \Vhat{x}_j , & i \neq j \\
	\frac{1}{1-p} \Vhat{x}_i^2, & i = j
	\end{cases}
	\]
	
	We realized this method and the result is shown in the figure below.
	
	\subsection{Deriving the uniform noise case}
	
	In the denoising problem, however, we are faced with noised information instead of missing values. We assume each noise pixel has a uniformly distributed color value independently. Thus, 
	\[
	\Vhat{x}_i =
	\begin{cases}
	\V{x}_i, & \textrm{w.p. } 1-p \\
	U_i, & \textrm{w.p. } p
	\end{cases},
	\]
	where $U_i$ is a uniformly distributed noise from color spectrum. For simplicity, we assume $U_i \sim \textrm{Unif}(0,1)$. From this assumption, an unbiased estimator for $C$ can be derived as
	\[
	\hat{C}_{ij} =
	\begin{cases}
	\frac{ \Vhat{x}_i \Vhat{x}_j - \frac{1}{2} \Vhat{x}_i - \frac{1}{2} \Vhat{x}_j + \frac{1}{4}p^2 }{(1-p)^2}, & i \neq j \\
	\frac{\Vhat{x}_i^2 - \frac{1}{3}p }{1-p}, & i = j
	\end{cases}
	\]
	The performance of this approach relies on the accuracy of estimating noise rate $p$. It can perform better than the previous method with an accurate $p$. 
	
	\section{Prospect}
	
	\subsection{Detecting Noises}
	
	If we can detect the noised pixels, we can replace those pixels with some properly selected ones to make the image as continuous and smooth as possible. However, detecting the noises can be a tough task. An simple idea is, by assuming the original image to be generally smooth, we can label those pixels significantly different from other surrounding pixels as noised ones. Details need further discussion.
	
	\subsection{Inferring Noises}
	
	If the noises have a uniformly distributed color, it is entirely possible that a noised pixel doesn't have a significantly different color from the surrounding pixels. If we have to make a binary inference whether or not such a pixel is a noised one, there will be a high rate of either Type I or Type II error. Considering such a dilemma, we may estimate the probability that each pixel is a noised one. By doing so, we can estimate the matrix $C$ with some statistical methods.
	
	\newpage
	
	\section{Appendix}
	
	\subsection{Denoising on a single image}
	
	\begin{figure}[h]
		\centering
		
		\begin{subfigure}{.45\textwidth}
			\centering
			\includegraphics[width=\linewidth]{Missing}
			\caption{An image with $p = 2$ missing pixels and POPCA solution with $dim = 40$}
			\label{fig:missing}
		\end{subfigure}%
		\hfill
		\begin{subfigure}{.45\textwidth}
			\centering
			\includegraphics[width=\linewidth]{Color}
			\caption{An image with $p = 2$ random color noise and POPCA solution with $dim = 40$}
			\label{fig:color}
		\end{subfigure}
		
		\caption{A figure with two subfigures}
		\label{fig:badge}
	\end{figure}
	
\end{document}
